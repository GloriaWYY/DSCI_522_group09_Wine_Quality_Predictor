{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da52cc7-d6ad-4b36-915d-10f2c4516f32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83919a8-acfc-4b6c-92d9-66494c30c8f6",
   "metadata": {},
   "source": [
    "In order to classify the wine qualities, we chose to use three different models, including support vector machine with linear kernal, logistic regression, and random forest. We carried out 5-fold cross validation on all three models to find the best performing model based on the cross validation scores. During the EDA stage of the project, we observed class imbalance in our data set. Therefore, we decided to use several scoring metrics such as f1 score, Receiver Operating Characteristic - One versus Rest(roc_auc_ovr), Area under the curve - One versus One(roc_auc_ovo). Based on the cross validation results as shown below, we select the random forest model as our best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e0e75b-55f9-4b23-ba36-33d305aecbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-input\",\n",
    "    ]\n",
    "}\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719a66aa-2acd-4311-b0f0-40c79d804bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>test_roc_auc_ovr</th>\n",
       "      <th>train_roc_auc_ovr</th>\n",
       "      <th>test_roc_auc_ovo</th>\n",
       "      <th>train_roc_auc_ovo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.009 (+/- 0.001)</td>\n",
       "      <td>0.026 (+/- 0.001)</td>\n",
       "      <td>0.333 (+/- 0.013)</td>\n",
       "      <td>0.333 (+/- 0.004)</td>\n",
       "      <td>0.193 (+/- 0.011)</td>\n",
       "      <td>0.200 (+/- 0.005)</td>\n",
       "      <td>0.496 (+/- 0.007)</td>\n",
       "      <td>0.501 (+/- 0.003)</td>\n",
       "      <td>0.496 (+/- 0.007)</td>\n",
       "      <td>0.500 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>3.333 (+/- 0.173)</td>\n",
       "      <td>0.208 (+/- 0.009)</td>\n",
       "      <td>0.532 (+/- 0.017)</td>\n",
       "      <td>0.539 (+/- 0.004)</td>\n",
       "      <td>0.241 (+/- 0.008)</td>\n",
       "      <td>0.244 (+/- 0.002)</td>\n",
       "      <td>0.746 (+/- 0.011)</td>\n",
       "      <td>0.755 (+/- 0.009)</td>\n",
       "      <td>0.730 (+/- 0.012)</td>\n",
       "      <td>0.738 (+/- 0.010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.202 (+/- 0.013)</td>\n",
       "      <td>0.025 (+/- 0.001)</td>\n",
       "      <td>0.546 (+/- 0.014)</td>\n",
       "      <td>0.550 (+/- 0.004)</td>\n",
       "      <td>0.325 (+/- 0.012)</td>\n",
       "      <td>0.330 (+/- 0.005)</td>\n",
       "      <td>0.764 (+/- 0.016)</td>\n",
       "      <td>0.777 (+/- 0.003)</td>\n",
       "      <td>0.759 (+/- 0.014)</td>\n",
       "      <td>0.772 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.602 (+/- 0.014)</td>\n",
       "      <td>0.074 (+/- 0.002)</td>\n",
       "      <td>0.652 (+/- 0.012)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.501 (+/- 0.025)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.852 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "      <td>0.847 (+/- 0.003)</td>\n",
       "      <td>1.000 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              fit_time         score_time      test_accuracy  \\\n",
       "Dummy                0.009 (+/- 0.001)  0.026 (+/- 0.001)  0.333 (+/- 0.013)   \n",
       "SVC                  3.333 (+/- 0.173)  0.208 (+/- 0.009)  0.532 (+/- 0.017)   \n",
       "Logistic Regression  0.202 (+/- 0.013)  0.025 (+/- 0.001)  0.546 (+/- 0.014)   \n",
       "Random Forest        0.602 (+/- 0.014)  0.074 (+/- 0.002)  0.652 (+/- 0.012)   \n",
       "\n",
       "                        train_accuracy      test_f1_macro     train_f1_macro  \\\n",
       "Dummy                0.333 (+/- 0.004)  0.193 (+/- 0.011)  0.200 (+/- 0.005)   \n",
       "SVC                  0.539 (+/- 0.004)  0.241 (+/- 0.008)  0.244 (+/- 0.002)   \n",
       "Logistic Regression  0.550 (+/- 0.004)  0.325 (+/- 0.012)  0.330 (+/- 0.005)   \n",
       "Random Forest        1.000 (+/- 0.000)  0.501 (+/- 0.025)  1.000 (+/- 0.000)   \n",
       "\n",
       "                      test_roc_auc_ovr  train_roc_auc_ovr   test_roc_auc_ovo  \\\n",
       "Dummy                0.496 (+/- 0.007)  0.501 (+/- 0.003)  0.496 (+/- 0.007)   \n",
       "SVC                  0.746 (+/- 0.011)  0.755 (+/- 0.009)  0.730 (+/- 0.012)   \n",
       "Logistic Regression  0.764 (+/- 0.016)  0.777 (+/- 0.003)  0.759 (+/- 0.014)   \n",
       "Random Forest        0.852 (+/- 0.003)  1.000 (+/- 0.000)  0.847 (+/- 0.003)   \n",
       "\n",
       "                     train_roc_auc_ovo  \n",
       "Dummy                0.500 (+/- 0.003)  \n",
       "SVC                  0.738 (+/- 0.010)  \n",
       "Logistic Regression  0.772 (+/- 0.003)  \n",
       "Random Forest        1.000 (+/- 0.000)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-input\",\n",
    "    ]\n",
    "}\n",
    "pd.read_csv(\"../../results/cross_val_results.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a0e0c-95b8-4148-86a3-5d7f9a0aee83",
   "metadata": {},
   "source": [
    "To find the best parameters of the random forest model, we perform hyperparameter optimization on n_estimators and max_depth in the random forest model. The optimal hyperparameter results are shown in the table below. We observed that the optimal n_estimators was 4641 and the max_depth was 26. During the hyperparameter optimization, we used roc_auc_ovr as our scoring metrics. The validation score for the optimized model is 0.867. Our model performs acceptable, and the test score for the optimized model is 0.685."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390ac176-d1dc-4195-952e-c0fb42102281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest Best n_estimators</th>\n",
       "      <th>Random Forest Best max_depth</th>\n",
       "      <th>Random Forest Best Score</th>\n",
       "      <th>Random Forest Roc_Auc Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4641</td>\n",
       "      <td>26</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random Forest Best n_estimators  Random Forest Best max_depth  \\\n",
       "0                             4641                            26   \n",
       "\n",
       "   Random Forest Best Score  Random Forest Roc_Auc Test Score  \n",
       "0                     0.867                             0.685  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-input\",\n",
    "    ]\n",
    "}\n",
    "pd.read_csv(\"../../results/random_forest_results.csv\", index_col = 0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c025fea6-4e25-4935-89ac-7c68af026402",
   "metadata": {},
   "source": [
    "In addition, we plotted the confusion matrix of model performance on test data to get insights of how our model performed. Our model was mostly confused among the quality classes of 5, 6 and 7. This is probably because the features do not have well separated distributions with respect to these classes. This is in line with what we observed in the preliminary exploratory data analysis. Although the model did not perform great on this classification task, our main task does not include any sensitive prediction. Therefore, we are relatively confident to share the results of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2597d4-16cd-4500-b4fb-0e2d7248006c",
   "metadata": {},
   "source": [
    "![alt text](../../results/test_cm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024a664-ec72-4a21-8432-fa30abf44866",
   "metadata": {},
   "source": [
    "Among all the features that our data set had, alcohol, density and volatile acidity were the top 3 important features. On the other hand, fixed acidity, type-white and type-red were the least important features. This result is also consistent with our initial exploratory data analysis. The features alcohol, density and volatile acidity were among the most important features that we observed during exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8466de1-eb5f-45c5-852e-b2c613772f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_white</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_red</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature Importances\n",
       "alcohol                             0.116\n",
       "density                             0.094\n",
       "volatile acidity                    0.091\n",
       "total sulfur dioxide                0.082\n",
       "chlorides                           0.079\n",
       "free sulfur dioxide                 0.079\n",
       "residual sugar                      0.077\n",
       "sulphates                           0.076\n",
       "pH                                  0.073\n",
       "citric acid                         0.071\n",
       "fixed acidity                       0.067\n",
       "type_white                          0.003\n",
       "type_red                            0.003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-input\",\n",
    "    ]\n",
    "}\n",
    "pd.read_csv(\"../../results/feature_importances.csv\", index_col = 0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2642eae9-7929-45bc-bcd2-ce4b90d6a215",
   "metadata": {},
   "source": [
    "Furthermore, to improve this model in future, we suggest to gather more wine samples from lower quality class and higher quality class to fix the severe class imbalance issue in the dataset so that it could be used to classify the wine qualities properly in the real world. Also, we could carry out feature engineering like adding polynomial features to our dataset or finding new features, and perform feature elimination to remove unimportant features.\n",
    "\n",
    "In conclusion, we used the random forest model which has feature interaction and gives better test scores than the other two models we tried. In reality, the overall performance of the model may differ from what is observed here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wine_quality_predictor]",
   "language": "python",
   "name": "conda-env-wine_quality_predictor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
